### This is the README for John Neal's Mini Project 2 for EC 601 at Boston Univeristy.

### This project makes use of the 7-class dataset found at http://ai.stanford.edu/~bangpeng/ppmi.html. A README for this dataset is included in this bundle.

### It also makes use of multiple borrowed modules including:

-- labelImg:

(Not included in this project folder, but can be found here: https://github.com/tzutalin/labelImg) [for labeling images and drawing bounding boxes]

-- xml2csv.py:

(Modified by John Neal, borrowed from https://github.com/datitran/raccoon_dataset/blob/master/xml_to_csv.py) [to convert xml files from labelImg to .csv]

-- classfy_image.py:

(Modified by John Neal, borrowed from https://github.com/tensorflow/models/blob/master/tutorials/image/imagenet/classify_image.py) [to take image input as a jpg and classify it depending on classses]

### Modifications of these modules are specified in the modules themselves.

### Other files included are:

-- The dataset split up into training, testing, and verification sets.
-- XML files generated by labelImg
-- CSV file generated by  xml2csv.py

### How this meets project goals:

# classify_image.py is able to classify between flute or saxophone and make an assesment of the top prediction of whether that prediction is correct or incorrect according to the label.

# The dataset is split into training, testing, and verification sets.

-- I tried to roughly follow the proportionality specified here: https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7.

-- I also tried to make sure the dataset was diverse. It really is. There is a good mixture of images: some with a single flute, others with multiple,  some with objects that look like flutes but are not, some that are good quality and others that are blurry, some with discoloration due to age of the photo. I do think the dataset could use more images with object that look like flutes, held in the position one holds the flute, but are not flutes.

-- I should also specify that I took saxophones to be the standard saxophone shape such as this: https://media.wwbw.com/is/image/MMGS7/Student-Series-Tenor-Saxophone-Model-AATS-301/585011000000000-00-500x500.jpg.

# Images were tagged by myself using labelImg (very helpful software).

# The comparison between two different systems is provided in the file DLComparison.md

### Other items to note:

-- The tutorial at https://www.tensorflow.org/tutorials/keras/basic_classification was very interesting and was originally going to be the way I styled my project. But I realized how complicated processing the jpg images into RGB numpy arrays and then Greyscale was. Also, the project only specifies to use TensorFlow to classify between two sets of images. So in the interest of handing something in, I opted for this simpler model, though I find the other one much more interesting (as it shows what is going on on a deeper level) and will experiment with it in my freetime.
